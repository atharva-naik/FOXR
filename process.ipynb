{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e69b7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import datetime\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "481d85db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'incident_state', 'active', 'reassignment_count',\n",
       "       'reopen_count', 'sys_mod_count', 'made_sla', 'caller_id', 'opened_by',\n",
       "       'opened_at', 'sys_created_by', 'sys_created_at', 'sys_updated_by',\n",
       "       'sys_updated_at', 'contact_type', 'location', 'category', 'subcategory',\n",
       "       'u_symptom', 'cmdb_ci', 'impact', 'urgency', 'priority',\n",
       "       'assignment_group', 'assigned_to', 'knowledge',\n",
       "       'u_priority_confirmation', 'notify', 'problem_id', 'rfc', 'vendor',\n",
       "       'caused_by', 'closed_code', 'resolved_by', 'resolved_at', 'closed_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ServiceNowEventLog.csv\")\n",
    "df.columns\n",
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a484f181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-100',\n",
       " 'Active',\n",
       " 'Awaiting Evidence',\n",
       " 'Awaiting Problem',\n",
       " 'Awaiting User Info',\n",
       " 'Awaiting Vendor',\n",
       " 'Closed',\n",
       " 'New',\n",
       " 'Resolved'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incident_states = set(df['incident_state'])\n",
    "incident_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecd8066b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Active',\n",
       " 'Awaiting Evidence',\n",
       " 'Awaiting Problem',\n",
       " 'Awaiting User Info',\n",
       " 'Awaiting Vendor',\n",
       " 'Closed',\n",
       " 'New',\n",
       " 'Resolved']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb12df",
   "metadata": {},
   "source": [
    "## **Data Prepocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8122e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # numerical features.\n",
    "# num_feats = [\n",
    "#     'reassignment_count',\n",
    "#     'reopen_count',\n",
    "#     'sys_mod_count',\n",
    "    \n",
    "# ]\n",
    "# # datetime features (ordinal).\n",
    "# # compute timestamp difference between opened_at and ['sys_created_at', 'sys_updated_at', 'resolved_at']\n",
    "# # ignore closed at.\n",
    "# date_feats = [\n",
    "#     'opened_at',\n",
    "#     'sys_created_at',\n",
    "#     'sys_updated_at',\n",
    "#     'resolved_at' \n",
    "# ]\n",
    "# # categorical features.\n",
    "# # priority is calculated from impact and urgency\n",
    "# categ_feats = [\n",
    "#     'incident state', \n",
    "#     'active', 'made_sla',\n",
    "#     'impact', 'urgency',\n",
    "#     'priority', 'knowledge',\n",
    "#     'u_priority_confirmation',\n",
    "#     'notify', \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60c7e7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24918 unique incidents\n",
      "5245 unique victims\n",
      "846 unique updaters\n",
      "225 unique locations\n",
      "51 unique affected items\n",
      "5 unique vendors\n",
      "79 unique support groups\n",
      "235 unique report assignees\n",
      "253 unique problems\n"
     ]
    }
   ],
   "source": [
    "unique_incidents = set(df['number']) # Incident class\n",
    "unique_openers = set(df['opened_by']) # User class\n",
    "unique_victims = set(df['caller_id']) # User class\n",
    "unique_locations = set(df['location']) # Location class\n",
    "unique_updaters = set(df['sys_updated_by']) # User class \n",
    "unique_affected_items = set(df['cmdb_ci']) # Item class (report affected items)\n",
    "unique_vendors = set(df['vendor']) # vendor in charge of incident (cat)\n",
    "unique_support_groups = set(df['assignment_group']) # UserGroup class\n",
    "unique_assignees = set(df['assigned_to']) # User class (user in charge of incident)\n",
    "unique_problems = set(df['problem_id']) # Problem class (problem associated with id) \n",
    "# ignore: closed_at\n",
    "\n",
    "# unique problems\n",
    "# location\n",
    "# vendor (cat)\n",
    "\n",
    "# RFC class ()\n",
    "print(f\"{len(unique_incidents)} unique incidents\")\n",
    "# print(f\"{len(unique_callers)} unique openers\")\n",
    "print(f\"{len(unique_victims)} unique victims\")\n",
    "print(f\"{len(unique_updaters)} unique updaters\")\n",
    "print(f\"{len(unique_locations)} unique locations\")\n",
    "print(f\"{len(unique_affected_items)} unique affected items\")\n",
    "print(f\"{len(unique_vendors)} unique vendors\")\n",
    "print(f\"{len(unique_support_groups)} unique support groups\")\n",
    "print(f\"{len(unique_assignees)} unique report assignees\")\n",
    "print(f\"{len(unique_problems)} unique problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f3510d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclasses\n",
    "# class User:\n",
    "#     id: str\n",
    "    \n",
    "#     def __call__(self, **args) -> None:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f27358cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServiceNowDataset:\n",
    "    def __init__(self, records: List[dict], \n",
    "                 id: str=\"number\", target: str=\"resolved_at\"):\n",
    "        self.id = id\n",
    "        self.target = target\n",
    "        self.t_ref_key = 'opened_at'\n",
    "        self.t_fmt_str = \"%d/%m/%Y %H:%M\"\n",
    "        self.time_feats = [\n",
    "            'sys_created_at',\n",
    "            'sys_updated_at',\n",
    "            'resolved_at' \n",
    "        ]\n",
    "        self.num_feats = [\n",
    "            'reassignment_count',\n",
    "            'reopen_count',\n",
    "            'sys_mod_count',\n",
    "\n",
    "        ]\n",
    "        self.categ_feats = [\n",
    "            'incident_state', \n",
    "            'impact', 'urgency',\n",
    "            'priority', \n",
    "        ]\n",
    "        self.bool_feats = [\n",
    "            'active', 'made_sla', 'knowledge',\n",
    "            'u_priority_confirmation',  \n",
    "        ]\n",
    "        self.categ_map = {\n",
    "            \"incident_state\": [\n",
    "                 'Active', \n",
    "                 'Awaiting Evidence',\n",
    "                 'Awaiting Problem',\n",
    "                 'Awaiting User Info',\n",
    "                 'Awaiting Vendor',\n",
    "                 'Closed',\n",
    "                 'New',\n",
    "                 'Resolved'\n",
    "            ],\n",
    "            \"urgency\": [\n",
    "                '1 - High', \n",
    "                '2 - Medium', \n",
    "                '3 - Low'\n",
    "            ],\n",
    "            \"impact\": [\n",
    "                '1 - High', \n",
    "                '2 - Medium', \n",
    "                '3 - Low'\n",
    "            ],\n",
    "            \"priority\": [\n",
    "                '1 - Critical', \n",
    "                '2 - High', \n",
    "                '3 - Moderate', \n",
    "                '4 - Low'\n",
    "            ],\n",
    "        }\n",
    "        self.features = self.time_feats + self.num_feats\n",
    "        self.data = self(records, train=True)\n",
    "        self.raw_features = records[0].keys()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.data)\n",
    "    \n",
    "    def __call__(self, data: List[dict], train: bool=False):\n",
    "        i = 0\n",
    "        new_data = []\n",
    "        for rec in tqdm(data, desc=\"processing data\"):\n",
    "            proc_rec = {}\n",
    "            t_rec = self.convert_time_fields(rec)\n",
    "            proc_rec.update(t_rec)\n",
    "            for feat in self.num_feats:\n",
    "                proc_rec[feat] = rec[feat]\n",
    "            categ_rec = self.encode_categ_onehot(rec)\n",
    "            bool_rec = self.encode_bool(rec)\n",
    "            proc_rec.update(categ_rec)\n",
    "            proc_rec.update(bool_rec)\n",
    "            proc_rec[\"notify\"] = [\n",
    "                'Do Not Notify', \n",
    "                'Send Email',\n",
    "            ].index(rec[\"notify\"])\n",
    "            proc_rec[\"id\"] = rec[\"number\"]\n",
    "            new_data.append(proc_rec)\n",
    "            i += 1\n",
    "            # if i == 100: break\n",
    "        return new_data\n",
    "    \n",
    "    def __getitem__(self, i: int):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def encode_categ_onehot(self, rec: dict):\n",
    "        categ_rec = {}\n",
    "        for feat in self.categ_feats:\n",
    "            map_ = self.categ_map[feat]\n",
    "            vec = [0 for i in range(len(map_))]\n",
    "            try: vec[map_.index(rec[feat])] = 1\n",
    "            except ValueError: pass\n",
    "            categ_rec[feat] = vec\n",
    "            \n",
    "        return categ_rec\n",
    "    \n",
    "    def encode_bool(self, rec: dict):\n",
    "        bool_rec = {}\n",
    "        for feat in self.bool_feats:\n",
    "            bool_rec[feat] = int(rec[feat])\n",
    "        \n",
    "        return bool_rec\n",
    "        \n",
    "    def convert_time_fields(self, rec: dict):\n",
    "        t_ref = datetime.datetime.strptime(\n",
    "            rec[self.t_ref_key], \n",
    "            self.t_fmt_str,\n",
    "        ).timestamp()\n",
    "        t_rec = {}\n",
    "        for feat in self.time_feats:\n",
    "            val = rec[feat]\n",
    "            try:\n",
    "                t = datetime.datetime.strptime(\n",
    "                    val, self.t_fmt_str,\n",
    "                ).timestamp()\n",
    "                t_rec[feat] = t-t_ref\n",
    "            except ValueError:\n",
    "                t_rec[feat] = -1 # encode missing values as -1\n",
    "        \n",
    "        return t_rec\n",
    "    \n",
    "    def tolist(self):\n",
    "        X, y = [], []\n",
    "        for rec in tqdm(self.data, desc=\"converting to list\"):\n",
    "            rec_list = []\n",
    "            for k, v in rec.items():\n",
    "                if k == self.target: \n",
    "                    y.append(v)\n",
    "                    continue\n",
    "                # skip these fields.\n",
    "                if isinstance(v, list):\n",
    "                    rec_list += v\n",
    "                elif isinstance(v, (float, int)):\n",
    "                    rec_list += [v]\n",
    "            X.append(rec_list)\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    def aggregate(self, inplace=False):\n",
    "        import copy\n",
    "        cid = \"\"\n",
    "        data = []\n",
    "        for rec in tqdm(self.data, desc=\"aggregating\"):\n",
    "            id = rec[\"id\"]\n",
    "            if cid != id: \n",
    "                cid = id\n",
    "                N = 1\n",
    "                state = rec\n",
    "            else:\n",
    "                for feat in self.num_feats:\n",
    "                    state[feat] = (N*state[feat]+rec[feat])/(N+1) \n",
    "                for feat in self.categ_feats:\n",
    "                    state[feat] = (np.array(rec[feat]) + np.array(state[feat])).tolist()\n",
    "                for feat in self.bool_feats+self.time_feats:\n",
    "                    state[feat] = rec[feat]\n",
    "                N += 1\n",
    "            data.append(copy.deepcopy(state))\n",
    "        if inplace: self.data = data\n",
    "        else: return data\n",
    "        \n",
    "    def tonumpy(self):\n",
    "        X, y = self.tolist()\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3818a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ServiceNowEventLog.csv\")\n",
    "df_records = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "665ed9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing data: 100%|██████████| 141712/141712 [00:12<00:00, 11246.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sys_created_at': 53076, 'resolved_at': 3141}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ServiceNowDataset(df_records)\n",
    "# print(data.raw_features)\n",
    "# print(data.features)\n",
    "# pprint(data.data)\n",
    "print(len(data))\n",
    "\n",
    "# sys created at info is missing in some cases.\n",
    "missing_time = {'sys_created_at': 0, 'resolved_at': 0}\n",
    "for i, rec in enumerate(data):\n",
    "    \n",
    "    for k in data.time_feats:\n",
    "        if rec[k] == -1:\n",
    "            missing_time[k] += 1\n",
    "missing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd5681",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95bd8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(set(i['id'] for i in data)))\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62e4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converting to list: 100%|██████████| 141712/141712 [00:01<00:00, 92655.72it/s] \n"
     ]
    }
   ],
   "source": [
    "X, y = data.tonumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a1b8255a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.200e+02, 4.200e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "         0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "         1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [4.200e+02, 2.742e+04, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "         1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00]]),\n",
       " array([ 36780.,  36780.,  36780.,  36780., 105120., 105120., 105120.,\n",
       "        105120., 105120., 105120.]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2], y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf964a",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f8521d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36780.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = normalize(X, norm=\"l2\")\n",
    "X_norm[0]\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "647357af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_tree = DecisionTreeRegressor(random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57c93956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model_class, seeds=[2022], **args):\n",
    "        self.models = {} \n",
    "        self.seeds = seeds\n",
    "        for seed in self.seeds: \n",
    "            self.models[seed] = model_class(**args, random_state=seed)\n",
    "    \n",
    "    def evaluate(self, X, y, folds=5, \n",
    "                 scoring=\"r2\", **args):\n",
    "        all_seed_scores = []\n",
    "        print(\"scoring:\", scoring)\n",
    "        pbar = tqdm(self.seeds, desc=\"eval(seed='NA')\")\n",
    "        for seed in pbar:\n",
    "            pbar.set_description(f\"eval(seed={seed})\")\n",
    "            all_seed_scores.append(cross_val_score(\n",
    "                self.models[seed], X, y, \n",
    "                cv=folds, scoring=scoring, \n",
    "                **args,\n",
    "            ))\n",
    "        all_seed_scores = np.stack([scores.mean() for scores in all_seed_scores])\n",
    "                                 \n",
    "        return all_seed_scores, all_seed_scores.mean(), all_seed_scores.var()**0.5\n",
    "    \n",
    "seeds = [1,2,3,4,5,6,7,8,9,2022]\n",
    "folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4d4b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval(seed=1):   0%|          | 0/10 [00:00<?, ?it/s]   [Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   18.4s finished\n",
      "eval(seed=2):  10%|█         | 1/10 [00:18<02:46, 18.54s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.5s finished\n",
      "eval(seed=3):  20%|██        | 2/10 [00:31<02:00, 15.08s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.4s finished\n",
      "eval(seed=4):  30%|███       | 3/10 [00:43<01:37, 13.92s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.3s finished\n",
      "eval(seed=5):  40%|████      | 4/10 [00:56<01:19, 13.33s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.9s finished\n",
      "eval(seed=6):  50%|█████     | 5/10 [01:09<01:06, 13.20s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   13.3s finished\n",
      "eval(seed=7):  60%|██████    | 6/10 [01:22<00:53, 13.26s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.7s finished\n",
      "eval(seed=8):  70%|███████   | 7/10 [01:35<00:39, 13.10s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   13.3s finished\n",
      "eval(seed=9):  80%|████████  | 8/10 [01:48<00:26, 13.20s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.8s finished\n",
      "eval(seed=2022):  90%|█████████ | 9/10 [02:01<00:13, 13.12s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.6s finished\n",
      "eval(seed=2022): 100%|██████████| 10/10 [02:14<00:00, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=0.055±0.007 (10 folds, 10 seeds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = Evaluator(DecisionTreeRegressor, seeds=seeds)\n",
    "scores, mu, sigma = decision_tree.evaluate(\n",
    "    X_norm, y, n_jobs=4, \n",
    "    folds=folds, verbose=1,\n",
    "    scoring='explained_variance'\n",
    ")\n",
    "# mean absolute error\n",
    "# 'explained_variance'\n",
    "# 'max_error'\n",
    "# 'neg_mean_absolute_error'\n",
    "# 'neg_mean_squared_error'\n",
    "# 'neg_root_mean_squared_error'\n",
    "# 'neg_mean_squared_log_error'\n",
    "# 'neg_median_absolute_error'\n",
    "# 'r2'\n",
    "# 'neg_mean_poisson_deviance'\n",
    "# 'neg_mean_gamma_deviance'\n",
    "# 'neg_mean_absolute_percentage_error'\n",
    "print(f\"R²={mu:.3f}±{sigma:.3f} ({folds} folds, {len(seeds)} seeds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "daf96854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval(seed=1):   0%|          | 0/10 [00:00<?, ?it/s]   [Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=2):  10%|█         | 1/10 [01:32<13:48, 92.03s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=3):  20%|██        | 2/10 [03:00<12:01, 90.18s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=4):  30%|███       | 3/10 [04:28<10:24, 89.20s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=5):  40%|████      | 4/10 [05:57<08:53, 88.84s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=6):  50%|█████     | 5/10 [07:29<07:30, 90.10s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=7):  60%|██████    | 6/10 [09:00<06:01, 90.44s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=8):  70%|███████   | 7/10 [10:31<04:32, 90.71s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=9):  80%|████████  | 8/10 [12:03<03:01, 90.87s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=2022):  90%|█████████ | 9/10 [13:31<01:30, 90.21s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "eval(seed=2022): 100%|██████████| 10/10 [15:03<00:00, 90.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=0.045±0.000 (10 folds, 10 seeds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Evaluator(RandomForestRegressor, seeds=seeds, max_depth=2)\n",
    "scores, mu, sigma = random_forest.evaluate(\n",
    "    X_norm, y, n_jobs=4, \n",
    "    folds=folds, verbose=1,\n",
    "    scoring='r2'\n",
    ")\n",
    "print(f\"R²={mu:.3f}±{sigma:.3f} ({folds} folds, {len(seeds)} seeds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c87e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.241055344541257e-05"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d97cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean R² over 10 folds=0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   12.4s finished\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "tree_scores = []\n",
    "tree_scores = cross_val_score(\n",
    "    decision_tree, X_norm, y, \n",
    "    cv=folds, verbose=1, n_jobs=4\n",
    ").tolist()\n",
    "print(f\"mean R² over {folds} folds={scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c65cae7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean R² over 10 folds=0.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(\n",
    "    max_depth=2, random_state=2022\n",
    ")\n",
    "scores = cross_val_score(\n",
    "    random_forest, X_norm, y, \n",
    "    cv=folds, verbose=1, n_jobs=4\n",
    ")\n",
    "print(f\"mean R² over {folds} folds={scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2ab755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aggregating: 100%|██████████| 141712/141712 [00:10<00:00, 13785.61it/s]\n",
      "converting to list: 100%|██████████| 141712/141712 [00:01<00:00, 104026.67it/s]\n"
     ]
    }
   ],
   "source": [
    "data.aggregate(inplace=True)\n",
    "X, y = data.tonumpy()\n",
    "X_norm = normalize(X, norm=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f0d15fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval(seed=1):   0%|          | 0/10 [00:00<?, ?it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring: explained_variance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   36.8s finished\n",
      "eval(seed=2):  10%|█         | 1/10 [00:36<05:32, 36.90s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.8s finished\n",
      "eval(seed=3):  20%|██        | 2/10 [00:53<03:21, 25.14s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.0s finished\n",
      "eval(seed=4):  30%|███       | 3/10 [01:09<02:27, 21.03s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.6s finished\n",
      "eval(seed=5):  40%|████      | 4/10 [01:26<01:55, 19.33s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.8s finished\n",
      "eval(seed=6):  50%|█████     | 5/10 [01:43<01:32, 18.45s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   17.2s finished\n",
      "eval(seed=7):  60%|██████    | 6/10 [02:00<01:12, 18.06s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.6s finished\n",
      "eval(seed=8):  70%|███████   | 7/10 [02:17<00:52, 17.62s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.4s finished\n",
      "eval(seed=9):  80%|████████  | 8/10 [02:34<00:34, 17.27s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   17.2s finished\n",
      "eval(seed=2022):  90%|█████████ | 9/10 [02:51<00:17, 17.27s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:   16.4s finished\n",
      "eval(seed=2022): 100%|██████████| 10/10 [03:07<00:00, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=0.028±0.004 (10 folds, 10 seeds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = Evaluator(DecisionTreeRegressor, seeds=seeds)\n",
    "scores, mu, sigma = decision_tree.evaluate(\n",
    "    X_norm, y, n_jobs=4, \n",
    "    folds=folds, verbose=1,\n",
    "    scoring='explained_variance'\n",
    ")\n",
    "print(f\"R²={mu:.3f}±{sigma:.3f} ({folds} folds, {len(seeds)} seeds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "73331604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval(seed=1):   0%|          | 0/10 [00:00<?, ?it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring: explained_variance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=2):  10%|█         | 1/10 [01:47<16:11, 107.94s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=3):  20%|██        | 2/10 [03:35<14:21, 107.64s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=4):  30%|███       | 3/10 [05:22<12:32, 107.49s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=5):  40%|████      | 4/10 [07:11<10:47, 107.99s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=6):  50%|█████     | 5/10 [08:57<08:56, 107.37s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=7):  60%|██████    | 6/10 [10:47<07:12, 108.24s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.9min finished\n",
      "eval(seed=8):  70%|███████   | 7/10 [12:38<05:27, 109.23s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=9):  80%|████████  | 8/10 [14:24<03:36, 108.13s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.9min finished\n",
      "eval(seed=2022):  90%|█████████ | 9/10 [16:17<01:49, 109.64s/it][Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "eval(seed=2022): 100%|██████████| 10/10 [18:07<00:00, 108.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²=0.049±0.000 (10 folds, 10 seeds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Evaluator(RandomForestRegressor, seeds=seeds, max_depth=2)\n",
    "scores, mu, sigma = random_forest.evaluate(\n",
    "    X_norm, y, n_jobs=4, \n",
    "    folds=folds, verbose=1,\n",
    "    scoring='explained_variance'\n",
    ")\n",
    "print(f\"R²={mu:.3f}±{sigma:.3f} ({folds} folds, {len(seeds)} seeds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3cc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
